{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.0** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-machine-learning/resources/bANLa) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Evaluation\n",
    "\n",
    "In this assignment you'll train several models and evaluate how effectively they predict instances of fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Import the data from `fraud_data.csv`. What percentage of the observations in the dataset are instances of fraud?\n",
    "\n",
    "*This function should return a float between 0 and 1.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.176563</td>\n",
       "      <td>0.323798</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>1.047002</td>\n",
       "      <td>-0.368652</td>\n",
       "      <td>-0.728586</td>\n",
       "      <td>0.084678</td>\n",
       "      <td>-0.069246</td>\n",
       "      <td>-0.266389</td>\n",
       "      <td>0.155315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109627</td>\n",
       "      <td>-0.341365</td>\n",
       "      <td>0.057845</td>\n",
       "      <td>0.499180</td>\n",
       "      <td>0.415211</td>\n",
       "      <td>-0.581949</td>\n",
       "      <td>0.015472</td>\n",
       "      <td>0.018065</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.681109</td>\n",
       "      <td>-3.934776</td>\n",
       "      <td>-3.801827</td>\n",
       "      <td>-1.147468</td>\n",
       "      <td>-0.735540</td>\n",
       "      <td>-0.501097</td>\n",
       "      <td>1.038865</td>\n",
       "      <td>-0.626979</td>\n",
       "      <td>-2.274423</td>\n",
       "      <td>1.527782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652202</td>\n",
       "      <td>0.272684</td>\n",
       "      <td>-0.982151</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.360251</td>\n",
       "      <td>0.195321</td>\n",
       "      <td>-0.256273</td>\n",
       "      <td>0.056501</td>\n",
       "      <td>912.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.140729</td>\n",
       "      <td>0.453484</td>\n",
       "      <td>0.247010</td>\n",
       "      <td>2.383132</td>\n",
       "      <td>0.343287</td>\n",
       "      <td>0.432804</td>\n",
       "      <td>0.093380</td>\n",
       "      <td>0.173310</td>\n",
       "      <td>-0.808999</td>\n",
       "      <td>0.775436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003802</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>-0.121177</td>\n",
       "      <td>-0.304215</td>\n",
       "      <td>0.645893</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>-0.012115</td>\n",
       "      <td>-0.005945</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.107073</td>\n",
       "      <td>-3.298902</td>\n",
       "      <td>-0.184092</td>\n",
       "      <td>-1.795744</td>\n",
       "      <td>2.137564</td>\n",
       "      <td>-1.684992</td>\n",
       "      <td>-2.015606</td>\n",
       "      <td>-0.007181</td>\n",
       "      <td>-0.165760</td>\n",
       "      <td>0.869659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130648</td>\n",
       "      <td>0.329445</td>\n",
       "      <td>0.927656</td>\n",
       "      <td>-0.049560</td>\n",
       "      <td>-1.892866</td>\n",
       "      <td>-0.575431</td>\n",
       "      <td>0.266573</td>\n",
       "      <td>0.414184</td>\n",
       "      <td>62.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.314818</td>\n",
       "      <td>0.866839</td>\n",
       "      <td>-0.124577</td>\n",
       "      <td>-0.627638</td>\n",
       "      <td>2.651762</td>\n",
       "      <td>3.428128</td>\n",
       "      <td>0.194637</td>\n",
       "      <td>0.670674</td>\n",
       "      <td>-0.442658</td>\n",
       "      <td>0.133499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312774</td>\n",
       "      <td>-0.799494</td>\n",
       "      <td>-0.064488</td>\n",
       "      <td>0.953062</td>\n",
       "      <td>-0.429550</td>\n",
       "      <td>0.158225</td>\n",
       "      <td>0.076943</td>\n",
       "      <td>-0.015051</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  1.176563  0.323798  0.536927  1.047002 -0.368652 -0.728586  0.084678   \n",
       "1  0.681109 -3.934776 -3.801827 -1.147468 -0.735540 -0.501097  1.038865   \n",
       "2  1.140729  0.453484  0.247010  2.383132  0.343287  0.432804  0.093380   \n",
       "3 -1.107073 -3.298902 -0.184092 -1.795744  2.137564 -1.684992 -2.015606   \n",
       "4 -0.314818  0.866839 -0.124577 -0.627638  2.651762  3.428128  0.194637   \n",
       "\n",
       "         V8        V9       V10  ...         V21       V22       V23  \\\n",
       "0 -0.069246 -0.266389  0.155315  ...   -0.109627 -0.341365  0.057845   \n",
       "1 -0.626979 -2.274423  1.527782  ...    0.652202  0.272684 -0.982151   \n",
       "2  0.173310 -0.808999  0.775436  ...   -0.003802  0.058556 -0.121177   \n",
       "3 -0.007181 -0.165760  0.869659  ...    0.130648  0.329445  0.927656   \n",
       "4  0.670674 -0.442658  0.133499  ...   -0.312774 -0.799494 -0.064488   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  Class  \n",
       "0  0.499180  0.415211 -0.581949  0.015472  0.018065    4.67      0  \n",
       "1  0.165900  0.360251  0.195321 -0.256273  0.056501  912.00      0  \n",
       "2 -0.304215  0.645893  0.122600 -0.012115 -0.005945    1.00      0  \n",
       "3 -0.049560 -1.892866 -0.575431  0.266573  0.414184   62.10      0  \n",
       "4  0.953062 -0.429550  0.158225  0.076943 -0.015051    2.67      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fraud = pd.read_csv('../data/fraud_data.csv')\n",
    "df_fraud.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016410823768035772"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_one():\n",
    "    \n",
    "    df_fraud = pd.read_csv('../data/fraud_data.csv')\n",
    "    percent_fraud = df_fraud.Class.value_counts(1)[1]\n",
    "\n",
    "    # alternate method to get class percentages\n",
    "    #fraud = np.bincount(df_fraud.Class)[1] / len(df_fraud.Class)\n",
    "    return percent_fraud\n",
    "\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_fraud.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.176563</td>\n",
       "      <td>0.323798</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>1.047002</td>\n",
       "      <td>-0.368652</td>\n",
       "      <td>-0.728586</td>\n",
       "      <td>0.084678</td>\n",
       "      <td>-0.069246</td>\n",
       "      <td>-0.266389</td>\n",
       "      <td>0.155315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137258</td>\n",
       "      <td>-0.109627</td>\n",
       "      <td>-0.341365</td>\n",
       "      <td>0.057845</td>\n",
       "      <td>0.499180</td>\n",
       "      <td>0.415211</td>\n",
       "      <td>-0.581949</td>\n",
       "      <td>0.015472</td>\n",
       "      <td>0.018065</td>\n",
       "      <td>4.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.681109</td>\n",
       "      <td>-3.934776</td>\n",
       "      <td>-3.801827</td>\n",
       "      <td>-1.147468</td>\n",
       "      <td>-0.735540</td>\n",
       "      <td>-0.501097</td>\n",
       "      <td>1.038865</td>\n",
       "      <td>-0.626979</td>\n",
       "      <td>-2.274423</td>\n",
       "      <td>1.527782</td>\n",
       "      <td>...</td>\n",
       "      <td>1.341809</td>\n",
       "      <td>0.652202</td>\n",
       "      <td>0.272684</td>\n",
       "      <td>-0.982151</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.360251</td>\n",
       "      <td>0.195321</td>\n",
       "      <td>-0.256273</td>\n",
       "      <td>0.056501</td>\n",
       "      <td>912.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.140729</td>\n",
       "      <td>0.453484</td>\n",
       "      <td>0.247010</td>\n",
       "      <td>2.383132</td>\n",
       "      <td>0.343287</td>\n",
       "      <td>0.432804</td>\n",
       "      <td>0.093380</td>\n",
       "      <td>0.173310</td>\n",
       "      <td>-0.808999</td>\n",
       "      <td>0.775436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232185</td>\n",
       "      <td>-0.003802</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>-0.121177</td>\n",
       "      <td>-0.304215</td>\n",
       "      <td>0.645893</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>-0.012115</td>\n",
       "      <td>-0.005945</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.107073</td>\n",
       "      <td>-3.298902</td>\n",
       "      <td>-0.184092</td>\n",
       "      <td>-1.795744</td>\n",
       "      <td>2.137564</td>\n",
       "      <td>-1.684992</td>\n",
       "      <td>-2.015606</td>\n",
       "      <td>-0.007181</td>\n",
       "      <td>-0.165760</td>\n",
       "      <td>0.869659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348269</td>\n",
       "      <td>0.130648</td>\n",
       "      <td>0.329445</td>\n",
       "      <td>0.927656</td>\n",
       "      <td>-0.049560</td>\n",
       "      <td>-1.892866</td>\n",
       "      <td>-0.575431</td>\n",
       "      <td>0.266573</td>\n",
       "      <td>0.414184</td>\n",
       "      <td>62.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.314818</td>\n",
       "      <td>0.866839</td>\n",
       "      <td>-0.124577</td>\n",
       "      <td>-0.627638</td>\n",
       "      <td>2.651762</td>\n",
       "      <td>3.428128</td>\n",
       "      <td>0.194637</td>\n",
       "      <td>0.670674</td>\n",
       "      <td>-0.442658</td>\n",
       "      <td>0.133499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402329</td>\n",
       "      <td>-0.312774</td>\n",
       "      <td>-0.799494</td>\n",
       "      <td>-0.064488</td>\n",
       "      <td>0.953062</td>\n",
       "      <td>-0.429550</td>\n",
       "      <td>0.158225</td>\n",
       "      <td>0.076943</td>\n",
       "      <td>-0.015051</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  1.176563  0.323798  0.536927  1.047002 -0.368652 -0.728586  0.084678   \n",
       "1  0.681109 -3.934776 -3.801827 -1.147468 -0.735540 -0.501097  1.038865   \n",
       "2  1.140729  0.453484  0.247010  2.383132  0.343287  0.432804  0.093380   \n",
       "3 -1.107073 -3.298902 -0.184092 -1.795744  2.137564 -1.684992 -2.015606   \n",
       "4 -0.314818  0.866839 -0.124577 -0.627638  2.651762  3.428128  0.194637   \n",
       "\n",
       "         V8        V9       V10   ...         V20       V21       V22  \\\n",
       "0 -0.069246 -0.266389  0.155315   ...   -0.137258 -0.109627 -0.341365   \n",
       "1 -0.626979 -2.274423  1.527782   ...    1.341809  0.652202  0.272684   \n",
       "2  0.173310 -0.808999  0.775436   ...   -0.232185 -0.003802  0.058556   \n",
       "3 -0.007181 -0.165760  0.869659   ...    0.348269  0.130648  0.329445   \n",
       "4  0.670674 -0.442658  0.133499   ...    0.402329 -0.312774 -0.799494   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Amount  \n",
       "0  0.057845  0.499180  0.415211 -0.581949  0.015472  0.018065    4.67  \n",
       "1 -0.982151  0.165900  0.360251  0.195321 -0.256273  0.056501  912.00  \n",
       "2 -0.121177 -0.304215  0.645893  0.122600 -0.012115 -0.005945    1.00  \n",
       "3  0.927656 -0.049560 -1.892866 -0.575431  0.266573  0.414184   62.10  \n",
       "4 -0.064488  0.953062 -0.429550  0.158225  0.076943 -0.015051    2.67  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df_fraud.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use X_train, X_test, y_train, y_test for all of the following questions\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('../data/fraud_data.csv')\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? What is the recall?\n",
    "\n",
    "*This function should a return a tuple with two floats, i.e. `(accuracy score, recall score)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "\n",
    "# Precision = TP / (TP + FP)\n",
    "\n",
    "# Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
    "\n",
    "# F1 = 2 * Precision * Recall / (Precision + Recall) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.98525073746312686, 0.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two():\n",
    "    # recall = TP / (TP + FN)\n",
    "    # accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "    \n",
    "    from sklearn.dummy import DummyClassifier\n",
    "    from sklearn.metrics import recall_score#, accuracy_score\n",
    "    \n",
    "    # instead of importing the acc_score module, can just\n",
    "    # the .score method of the Classifier instance.\n",
    "    \n",
    "    clf_dummy = DummyClassifier(strategy = 'most_frequent')\n",
    "    clf_dummy.fit(X_train, y_train)\n",
    "    \n",
    "    y_dummy_pred = clf_dummy.predict(X_test)\n",
    "    \n",
    "    recall = recall_score(y_test, y_dummy_pred)\n",
    "#    accuracy = accuracy_score(y_test, y_dummy_pred)\n",
    "    accuracy = clf_dummy.score(X_test, y_test)\n",
    "    \n",
    "    return (accuracy, recall)\n",
    "\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Using X_train, X_test, y_train, y_test (as defined above), train a SVC classifer using the default parameters. What is the accuracy, recall, and precision of this classifier?\n",
    "\n",
    "*This function should a return a tuple with three floats, i.e. `(accuracy score, recall score, precision score)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99078171091445433, 0.375, 1.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_three():\n",
    "    # recall = TP / (TP + FN)\n",
    "    # accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "    # precision = TP / (TP + FP)\n",
    "    \n",
    "    from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    clf_svc = SVC().fit(X_train, y_train)\n",
    "    y_pred = clf_svc.predict(X_test)\n",
    "    \n",
    "#    scores = [accuracy_score, recall_score, precision_score]\n",
    "#    ans = (score(y_test, y_pred) for score in scores)\n",
    "    \n",
    "    accuracy = clf_svc.score(X_test, y_test)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "\n",
    "    return (accuracy, recall, precision)\n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Using the SVC classifier with parameters `{'C': 1e9, 'gamma': 1e-07}`, what is the confusion matrix when using a threshold of -220 on the decision function. Use X_test and y_test.\n",
    "\n",
    "*This function should return a confusion matrix, a 2x2 numpy array with 4 integers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5320,   24],\n",
       "       [  14,   66]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_four():\n",
    "    # precision_recall_curve = ROC? \n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    clf = SVC(C = 1e9, gamma = 1e-7).fit(X_train, y_train)\n",
    "    y_scores = clf.decision_function(X_test)\n",
    "    y_pred = []\n",
    "    for score in y_scores:\n",
    "        if score > -220:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "#    real_vs_pred = list(zip(y_test[:20], y_scores[:20]))\n",
    "#    for each in first_few:\n",
    "#        print(each)\n",
    "#    precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "#    confusion = confusion_matrix(y_test, y_scores)\n",
    "    \n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return confusion\n",
    "\n",
    "confusion_220 = answer_four()\n",
    "confusion_220"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Train a logisitic regression classifier with default parameters using X_train and y_train.\n",
    "\n",
    "For the logisitic regression classifier, create a precision recall curve and a roc curve using y_test and the probability estimates for X_test (probability it is fraud).\n",
    "\n",
    "Looking at the precision recall curve, what is the recall when the precision is `0.75`?\n",
    "\n",
    "Looking at the roc curve, what is the true positive rate when the false positive rate is `0.16`?\n",
    "\n",
    "*This function should return a tuple with two floats, i.e. `(recall, true positive rate)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.159618263473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.82499999999999996, 0.012500000000000001)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_five():\n",
    "        \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "\n",
    "    logit = LogisticRegression().fit(X_train, y_train)\n",
    "    y_scores = logit.decision_function(X_test)\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "    fpr_lg, tpr_lg, _ = roc_curve(y_test, y_scores)\n",
    "\n",
    "    recall_75 = recall[precision == .75]\n",
    "    \n",
    "    list_fpr = [each for each in fpr_lg]    \n",
    "    for each in list_fpr:\n",
    "        if ((each > 0.15) and (each < .17)):\n",
    "            idx_16 = each\n",
    "            print(idx_16)\n",
    "            break\n",
    "    tpr_16 = tpr_lg[idx_16]\n",
    "#    ans_tpr = np.array(tpr_16)\n",
    "    \n",
    "    return (recall_75[0], tpr_16)\n",
    "    \n",
    "answer_five()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Perform a grid search over the parameters listed below for a Logisitic Regression classifier, using recall for scoring and the default 3-fold cross validation.\n",
    "\n",
    "`'penalty': ['l1', 'l2']`\n",
    "\n",
    "`'C':[0.01, 0.1, 1, 10, 100]`\n",
    "\n",
    "From `.cv_results_`, create an array of the mean test scores of each parameter combination. i.e.\n",
    "\n",
    "|      \t| `l1` \t| `l2` \t|\n",
    "|:----:\t|----\t|----\t|\n",
    "| **`0.01`** \t|    ?\t|   ? \t|\n",
    "| **`0.1`**  \t|    ?\t|   ? \t|\n",
    "| **`1`**    \t|    ?\t|   ? \t|\n",
    "| **`10`**   \t|    ?\t|   ? \t|\n",
    "| **`100`**   \t|    ?\t|   ? \t|\n",
    "\n",
    "<br>\n",
    "\n",
    "*This function should return a 5 by 2 numpy array with 10 floats.* \n",
    "\n",
    "*Note: do not return a DataFrame, just the values denoted by '?' above in a numpy array.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_values = [{'C':[0.01, 0.1, 1, 10, 100]}, \n",
    "               {'penalty':['l1', 'l2']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='recall', verbose=0)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = LogisticRegression()\n",
    "grid_values = [{'C':[0.01, 0.1, 1, 10, 100], 'penalty':['l1', 'l2']}]\n",
    "grid_logit_recall = GridSearchCV(logit, param_grid = grid_values, scoring = 'recall')\n",
    "grid_logit_recall.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.07075373,  0.13825067,  0.09112589,  0.23810641,  0.21485003,\n",
       "         0.29121057,  0.33635036,  0.3446397 ,  0.47526574,  0.33310199]),\n",
       " 'mean_score_time': array([ 0.0028077 ,  0.0027403 ,  0.00266774,  0.00291491,  0.00399558,\n",
       "         0.00239428,  0.00268157,  0.00255132,  0.00279927,  0.00236734]),\n",
       " 'mean_test_score': array([ 0.66666667,  0.76086957,  0.80072464,  0.80434783,  0.8115942 ,\n",
       "         0.8115942 ,  0.80797101,  0.8115942 ,  0.80797101,  0.8115942 ]),\n",
       " 'mean_train_score': array([ 0.68115942,  0.77355072,  0.80615942,  0.8134058 ,  0.81884058,\n",
       "         0.81702899,  0.82427536,  0.82427536,  0.82427536,  0.82427536]),\n",
       " 'param_C': masked_array(data = [0.01 0.01 0.1 0.1 1 1 10 10 100 100],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_penalty': masked_array(data = ['l1' 'l2' 'l1' 'l2' 'l1' 'l2' 'l1' 'l2' 'l1' 'l2'],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'C': 0.01, 'penalty': 'l1'},\n",
       "  {'C': 0.01, 'penalty': 'l2'},\n",
       "  {'C': 0.1, 'penalty': 'l1'},\n",
       "  {'C': 0.1, 'penalty': 'l2'},\n",
       "  {'C': 1, 'penalty': 'l1'},\n",
       "  {'C': 1, 'penalty': 'l2'},\n",
       "  {'C': 10, 'penalty': 'l1'},\n",
       "  {'C': 10, 'penalty': 'l2'},\n",
       "  {'C': 100, 'penalty': 'l1'},\n",
       "  {'C': 100, 'penalty': 'l2'}),\n",
       " 'rank_test_score': array([10,  9,  8,  7,  3,  3,  5,  1,  5,  1], dtype=int32),\n",
       " 'split0_test_score': array([ 0.70652174,  0.80434783,  0.80434783,  0.82608696,  0.82608696,\n",
       "         0.82608696,  0.82608696,  0.83695652,  0.82608696,  0.83695652]),\n",
       " 'split0_train_score': array([ 0.69021739,  0.77173913,  0.79891304,  0.80978261,  0.82065217,\n",
       "         0.81521739,  0.82065217,  0.82065217,  0.82065217,  0.82065217]),\n",
       " 'split1_test_score': array([ 0.69565217,  0.75      ,  0.83695652,  0.83695652,  0.83695652,\n",
       "         0.83695652,  0.83695652,  0.83695652,  0.83695652,  0.83695652]),\n",
       " 'split1_train_score': array([ 0.67391304,  0.76630435,  0.79891304,  0.80434783,  0.80978261,\n",
       "         0.80978261,  0.81521739,  0.81521739,  0.81521739,  0.81521739]),\n",
       " 'split2_test_score': array([ 0.59782609,  0.72826087,  0.76086957,  0.75      ,  0.77173913,\n",
       "         0.77173913,  0.76086957,  0.76086957,  0.76086957,  0.76086957]),\n",
       " 'split2_train_score': array([ 0.67934783,  0.7826087 ,  0.82065217,  0.82608696,  0.82608696,\n",
       "         0.82608696,  0.83695652,  0.83695652,  0.83695652,  0.83695652]),\n",
       " 'std_fit_time': array([ 0.00845959,  0.0060736 ,  0.01523092,  0.02973088,  0.02431963,\n",
       "         0.04189113,  0.15884177,  0.02178232,  0.24882004,  0.05876882]),\n",
       " 'std_score_time': array([  7.60950594e-04,   6.58793414e-04,   4.79813835e-04,\n",
       "          7.51779589e-04,   1.88680715e-03,   4.38674348e-05,\n",
       "          4.47496550e-04,   2.25223673e-04,   2.75362002e-04,\n",
       "          2.75648266e-05]),\n",
       " 'std_test_score': array([ 0.04887948,  0.03199913,  0.03116785,  0.03868507,  0.02852901,\n",
       "         0.02852901,  0.03360007,  0.03586774,  0.03360007,  0.03586774]),\n",
       " 'std_train_score': array([ 0.00677836,  0.00677836,  0.01024792,  0.00923735,  0.00677836,\n",
       "         0.00677836,  0.00923735,  0.00923735,  0.00923735,  0.00923735])}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_logit_recall.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(grid_logit_recall.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.66666667,  0.76086957,  0.80072464,  0.80434783,  0.8115942 ,\n",
       "        0.8115942 ,  0.80797101,  0.8115942 ,  0.80797101,  0.8115942 ])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_logit_recall.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.070754</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.681159</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.706522</td>\n",
       "      <td>0.690217</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.597826</td>\n",
       "      <td>0.679348</td>\n",
       "      <td>0.008460</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.048879</td>\n",
       "      <td>0.006778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.138251</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.773551</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2'}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.771739</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.766304</td>\n",
       "      <td>0.728261</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.031999</td>\n",
       "      <td>0.006778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.091126</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>0.800725</td>\n",
       "      <td>0.806159</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.798913</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.798913</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.820652</td>\n",
       "      <td>0.015231</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.031168</td>\n",
       "      <td>0.010248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.238106</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.813406</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.809783</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.029731</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.009237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.214850</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.820652</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.809783</td>\n",
       "      <td>0.771739</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.024320</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.028529</td>\n",
       "      <td>0.006778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0       0.070754         0.002808         0.666667          0.681159    0.01   \n",
       "1       0.138251         0.002740         0.760870          0.773551    0.01   \n",
       "2       0.091126         0.002668         0.800725          0.806159     0.1   \n",
       "3       0.238106         0.002915         0.804348          0.813406     0.1   \n",
       "4       0.214850         0.003996         0.811594          0.818841       1   \n",
       "\n",
       "  param_penalty                        params  rank_test_score  \\\n",
       "0            l1  {'C': 0.01, 'penalty': 'l1'}               10   \n",
       "1            l2  {'C': 0.01, 'penalty': 'l2'}                9   \n",
       "2            l1   {'C': 0.1, 'penalty': 'l1'}                8   \n",
       "3            l2   {'C': 0.1, 'penalty': 'l2'}                7   \n",
       "4            l1     {'C': 1, 'penalty': 'l1'}                3   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.706522            0.690217           0.695652   \n",
       "1           0.804348            0.771739           0.750000   \n",
       "2           0.804348            0.798913           0.836957   \n",
       "3           0.826087            0.809783           0.836957   \n",
       "4           0.826087            0.820652           0.836957   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            0.673913           0.597826            0.679348      0.008460   \n",
       "1            0.766304           0.728261            0.782609      0.006074   \n",
       "2            0.798913           0.760870            0.820652      0.015231   \n",
       "3            0.804348           0.750000            0.826087      0.029731   \n",
       "4            0.809783           0.771739            0.826087      0.024320   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000761        0.048879         0.006778  \n",
       "1        0.000659        0.031999         0.006778  \n",
       "2        0.000480        0.031168         0.010248  \n",
       "3        0.000752        0.038685         0.009237  \n",
       "4        0.001887        0.028529         0.006778  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.66666667,  0.76086957,  0.80072464,  0.80434783,  0.8115942 ,\n",
       "        0.8115942 ,  0.80797101,  0.8115942 ,  0.80797101,  0.8115942 ])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_six():\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    logit = LogisticRegression()\n",
    "    grid_values = [{'C':[0.01, 0.1, 1, 10, 100], 'penalty':['l1', 'l2']}]\n",
    "    grid_logit_recall = GridSearchCV(logit, param_grid = grid_values, scoring = 'recall')\n",
    "    grid_logit_recall.fit(X_train,y_train)\n",
    "    \n",
    "    ans6 = grid_logit_recall.cv_results_['mean_test_score']\n",
    "    \n",
    "    return ans6\n",
    "\n",
    "clf_grid = answer_six()\n",
    "clf_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66666667,  0.76086957],\n",
       "       [ 0.80072464,  0.80434783],\n",
       "       [ 0.8115942 ,  0.8115942 ],\n",
       "       [ 0.80797101,  0.8115942 ],\n",
       "       [ 0.80797101,  0.8115942 ]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid.reshape(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the following function to help visualize results from the grid search\n",
    "def GridSearch_Heatmap(scores):\n",
    "    plt.figure()\n",
    "    sns.heatmap(scores.reshape(5,2), xticklabels=['l1','l2'], yticklabels=[0.01, 0.1, 1, 10, 100])\n",
    "    plt.yticks(rotation=0);\n",
    "\n",
    "GridSearch_Heatmap(answer_six())"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "5yX9Z",
   "launcher_item_id": "eqnV3",
   "part_id": "Msnj0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
